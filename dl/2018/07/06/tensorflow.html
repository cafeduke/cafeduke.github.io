<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Meta data -->
    <meta charset="utf-8">
<meta name="viewport" content="initial-scale=1, shrink-to-fit=no, width=device-width">
<meta http-equiv="x-ua-compatible" content="ie=edge">

    <!-- Window title -->
    <title>Tensorflow</title>

    <!-- CSS -->
    <!-- Material fonts from 'https://fonts.google.com' -->
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i,700,700i" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Roboto+Mono:300,300i,400,400i,500,500i,700,700i" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,500,500i,700,700i" rel="stylesheet"> 
<link href="https://fonts.googleapis.com/css?family=Vollkorn:300,300i,400,400i,500,500i,700,700i" rel="stylesheet"> 

<!-- Material Icon -->
<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

<!-- Font Awesome Icon -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">

<!-- Add Material CSS. Replace Bootstrap CSS -->
<link href="/assets/daemonite-material/css/material.min.css" rel="stylesheet">

<!-- Material Color Palette - CSS Classes -->
<link href="/assets/material-design-color-palette/css/material-design-color-palette.css" rel="stylesheet">

<!-- CafeDuke CSS - Project specific Classes  -->
<link href="/assets/css/main.css" rel="stylesheet" type="text/css">

<!-- CafeDuke Syntax CSS - Code syntax highlight -->
<link href="/assets/css/duke-dark.css" rel="stylesheet" type="text/css">


<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

    <!-- Navigation bar -->
    <nav class="navbar navbar-expand-lg navbar-dark mdc-bg-purple-900">
    
    

    <!-- Collapse Icon -->
    <a id="sidebar-toggle" class="navbar-brand text-white" href="">
        <i class="material-icons md-24">menu</i>
    </a>

    <!-- NavBar Heading -->
    <a class="navbar-brand text-white" href="/">Cafe Duke Notes</a>

    <!-- Collapse button -->
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">

        <!-- Links -->
        <ul class="navbar-nav mr-auto">


        </ul>
        <!-- Links -->

        <!-- Search form
        <form class="form-inline">
            <input class="form-control mr-sm-2" type="text" placeholder="Search" aria-label="Search">
        </form>
         -->

    </div>
    <!-- Collapsible content -->

</nav>


    <!-- Row: Content -->
    <div class="container-fluid m-0 p-0 h-100">

        <div class="row h-100 no-gutters">

            <!-- Column: Sidebar -->
            <div id="sidebar">

    <ul class="nav flex-column">

        <li class="nav-item">
            <a class="nav-link d-flex align-items-center" href="/">
                <i class="fas fa-home fa-lg"></i>
                <span class="nav-link-text">Home</span>
            </a>
        </li>

        <li class="nav-item">
            <a class="nav-link d-flex align-items-center" href="/java">
                <i class="fab fa-java fa-2x"></i>
                <span class="nav-link-text">Java</span>
            </a>
        </li>

        <li class="nav-item">
            <a class="nav-link d-flex align-items-center" href="/git">
                <i class="fab fa-git fa-lg"></i>
                <span class="nav-link-text">Git</span>
            </a>
        </li>

        <li class="nav-item">
            <a class="nav-link d-flex align-items-center" href="/cloud">
                <i class="material-icons md-24">cloud</i>
                <span class="nav-link-text">Cloud</span>
            </a>
        </li>

        <li class="nav-item">
            <a class="nav-link d-flex align-items-center" data-toggle="collapse" data-target="#child-dl" href="#">
                <i class="fas fa-cogs fa-lg"></i>
                <span class="nav-link-text">Deep Learning</span>
            </a>
            <div id="child-dl" class="collapse">
                <ul class="nav flex-column">
                    <li class="nav-item">
                        <a class="nav-link d-flex align-items-center" href="/deeplearning">
                            <span class="nav-link-text">Core</span>
                        </a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link d-flex align-items-center" href="/deeplearning/strategy">
                            <span class="nav-link-text">Strategy</span>
                        </a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link d-flex align-items-center" href="/deeplearning/cnn">
                            <span class="nav-link-text">CNN</span>
                        </a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link d-flex align-items-center" href="/deeplearning/rnn">
                            <span class="nav-link-text">RNN</span>
                        </a>
                    </li>
                </ul>
            </div>
        </li>

        <li class="nav-item">
            <a class="nav-link d-flex align-items-center" href="/django">
                <i class="fa fa-lg">dj</i>
                <span class="nav-link-text">Django</span>
            </a>
        </li>

        <li class="nav-item">
            <a class="nav-link d-flex align-items-center" href="/spring">
                <i class="fas fa-leaf fa-lg"></i>
                <span class="nav-link-text">Spring</span>
            </a>
        </li>

    </ul>
</div>


            <!-- Column: Content Wrapper -->
            <div class="col">
                <div id="content" class="w-100">
<div id="post-wrap" class="row d-flex justify-content-center">

    <div class="card col-md-10 col-xs-12 mt-5">

        <div class="card-header">
            <h1 class="post-title">Tensorflow</h1>
            <h6 class="card-subtitle post-meta"> 
                Friday, 6 July 2018
                
            </h6>            
        </div>

        <hr class="post-ruler">

        <div class="card-body">
            <nav>
  <h4>Table of Contents</h4>
<ol id="markdown-toc">
  <li>
<a href="#introduction" id="markdown-toc-introduction">Introduction</a>    <ol>
      <li><a href="#tensorflow-parallel-execution" id="markdown-toc-tensorflow-parallel-execution">Tensorflow Parallel Execution</a></li>
      <li>
<a href="#computation-graph" id="markdown-toc-computation-graph">Computation Graph</a>        <ol>
          <li><a href="#construction-phase---create-computation-graph" id="markdown-toc-construction-phase---create-computation-graph">Construction Phase $-$ Create Computation Graph</a></li>
          <li>
<a href="#execution-phase---run-computation-graph" id="markdown-toc-execution-phase---run-computation-graph">Execution Phase $-$ Run Computation Graph</a>            <ol>
              <li><a href="#session-without-with-block" id="markdown-toc-session-without-with-block">Session without <strong>with</strong> block</a></li>
              <li><a href="#session-using-with-block" id="markdown-toc-session-using-with-block">Session using <strong>with</strong> block</a></li>
              <li><a href="#default-session-and-global-variables-initializer" id="markdown-toc-default-session-and-global-variables-initializer">Default Session and Global variables initializer</a></li>
              <li><a href="#interactive-session-and-global-variables-initializer" id="markdown-toc-interactive-session-and-global-variables-initializer">Interactive Session and Global variables initializer</a></li>
            </ol>
          </li>
          <li><a href="#custom-computation-graph-object" id="markdown-toc-custom-computation-graph-object">Custom Computation Graph Object</a></li>
        </ol>
      </li>
    </ol>
  </li>
  <li><a href="#linear-regression-with-tensorflow" id="markdown-toc-linear-regression-with-tensorflow">Linear Regression With Tensorflow</a></li>
  <li>
<a href="#gradient-descent-with-tensorflow" id="markdown-toc-gradient-descent-with-tensorflow">Gradient Descent with Tensorflow</a>    <ol>
      <li><a href="#concept" id="markdown-toc-concept">Concept</a></li>
      <li><a href="#manually-computing-gradient-descent" id="markdown-toc-manually-computing-gradient-descent">Manually computing gradient descent</a></li>
      <li><a href="#autodiff" id="markdown-toc-autodiff">Autodiff</a></li>
      <li>
<a href="#optimizer" id="markdown-toc-optimizer">Optimizer</a>        <ol>
          <li><a href="#standard-optimizer" id="markdown-toc-standard-optimizer">Standard Optimizer</a></li>
          <li><a href="#momentum-optimizer" id="markdown-toc-momentum-optimizer">Momentum Optimizer</a></li>
        </ol>
      </li>
    </ol>
  </li>
  <li>
<a href="#placeholder-node" id="markdown-toc-placeholder-node">Placeholder Node</a>    <ol>
      <li><a href="#creating-placeholder-node" id="markdown-toc-creating-placeholder-node">Creating Placeholder Node</a></li>
      <li><a href="#dynamic-values-to-placeholder-node" id="markdown-toc-dynamic-values-to-placeholder-node">Dynamic values to Placeholder Node</a></li>
    </ol>
  </li>
  <li><a href="#scopes---namespace-for-nodes" id="markdown-toc-scopes---namespace-for-nodes">Scopes - Namespace for nodes</a></li>
  <li>
<a href="#sharing-variables" id="markdown-toc-sharing-variables">Sharing Variables</a>    <ol>
      <li><a href="#variable-in-a-scope" id="markdown-toc-variable-in-a-scope">Variable in a Scope</a></li>
      <li><a href="#example" id="markdown-toc-example">Example</a></li>
    </ol>
  </li>
  <li>
<a href="#saving-and-restoring-model" id="markdown-toc-saving-and-restoring-model">Saving and Restoring Model</a>    <ol>
      <li>
<a href="#saving-a-model" id="markdown-toc-saving-a-model">Saving a model</a>        <ol>
          <li><a href="#saving-specific-variables-only" id="markdown-toc-saving-specific-variables-only">Saving specific variables only</a></li>
        </ol>
      </li>
      <li><a href="#restoring-model" id="markdown-toc-restoring-model">Restoring model</a></li>
    </ol>
  </li>
  <li>
<a href="#visualize-graph--training-curves-using-tensorboard" id="markdown-toc-visualize-graph--training-curves-using-tensorboard">Visualize Graph / Training Curves using TensorBoard</a>    <ol>
      <li><a href="#construction-phase" id="markdown-toc-construction-phase">Construction phase</a></li>
      <li><a href="#execution-phase" id="markdown-toc-execution-phase">Execution phase</a></li>
      <li><a href="#visualize-log-dirs" id="markdown-toc-visualize-log-dirs">Visualize log dirs</a></li>
    </ol>
  </li>
</ol>

</nav>

<h1 id="introduction">Introduction</h1>

<p>Tensor flow is an open source, flexible, scalable, production-ready, python library that supports <strong>distributed computing</strong> for numerical computation $$-$$ particularly suited for <strong>large scale machine learning</strong></p>

<ul>
  <li>Tensor API <code class="language-plaintext highlighter-rouge">tensorflow.contrib.learn</code> is compatible with SciKit Learn</li>
  <li>
<strong>Tensor Board</strong> $$-$$ A great visualization tool</li>
  <li>
<strong>Cloud service</strong> to run Tensor flow graphs</li>
</ul>

<h2 id="tensorflow-parallel-execution">Tensorflow Parallel Execution</h2>

<p>Tensorflow operations (shortened as <strong>ops</strong>) can take any number of inputs and produce one ouput. Inputs and ouput are multidimensional array called <strong>tensors</strong>.</p>

<ul>
  <li>Addition, multiplication ops take two input and produce one output</li>
  <li>Constants and variables take no input (<em>source ops</em>)</li>
</ul>

<blockquote>
  <p>In Python Tensors are input/output NumPy arrays that have a type (typically float) and shape.</p>
</blockquote>

<ul>
  <li>A computation graph is created</li>
  <li>The graph can be broken down to chunks that can be executed in parallel on CPU/GPU</li>
</ul>

<p><img src="/assets/images/TensorEquation.png" alt="TensorEquation"></p>

<p>How <strong>big</strong> are we talking about $$-$$ Millions of features <code class="language-plaintext highlighter-rouge">n</code> with billions of instances <code class="language-plaintext highlighter-rouge">m</code></p>

<h2 id="computation-graph">Computation Graph</h2>

<h3 id="construction-phase---create-computation-graph">Construction Phase $-$ Create Computation Graph</h3>

<p>The following code <em>only</em> creates a <strong>default computation graph</strong> , but does NOT execute.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'x'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'y'</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="n">y</span> <span class="o">+</span> <span class="n">y</span> <span class="o">+</span> <span class="mi">2</span>
</code></pre></div></div>

<h3 id="execution-phase---run-computation-graph">Execution Phase $-$ Run Computation Graph</h3>

<p>To evaluate the graph it must be placed in <strong>tensor flow session</strong>.  The tensor flow session holds the variable values.</p>

<h4 id="session-without-with-block">Session without <strong>with</strong> block</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">session</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">initializer</span><span class="p">)</span>
<span class="n">session</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">initializer</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">session</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="n">session</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="session-using-with-block">Session using <strong>with</strong> block</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
    <span class="n">x</span><span class="p">.</span><span class="n">initializer</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">y</span><span class="p">.</span><span class="n">initializer</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<ul>
  <li>The session object is initialized as the default session.</li>
  <li>The session created is automatically closed a the end of the block</li>
</ul>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">f.eval()</code> is equivalent to calling <code class="language-plaintext highlighter-rouge">tf.get_default_session().run(f)</code></p>
</blockquote>

<h4 id="default-session-and-global-variables-initializer">Default Session and Global variables initializer</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Prepare an init node
</span><span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>

<span class="c1"># Note that a with block is required. No need to close session
</span><span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
    <span class="n">init</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="interactive-session-and-global-variables-initializer">Interactive Session and Global variables initializer</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Prepare an init node
</span><span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_ivariables_initializer</span><span class="p">()</span>

<span class="c1"># Interactive session automatically set itself as default session -- No with block
</span><span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">InteractiveSession</span><span class="p">()</span>
<span class="n">init</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

<span class="c1"># Session need to be closed
</span><span class="n">session</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="custom-computation-graph-object">Custom Computation Graph Object</h3>

<p>By default any node created is added to default graph.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span><span class="p">.</span><span class="n">graph</span> <span class="ow">is</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_default_graph</span><span class="p">()</span> <span class="c1"># True
</span></code></pre></div></div>

<p>A custom graph can be created and used as follows</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">graph</span><span class="p">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span><span class="p">.</span><span class="n">graph</span> <span class="ow">is</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_default_graph</span><span class="p">()</span> <span class="c1"># False
</span></code></pre></div></div>

<h1 id="linear-regression-with-tensorflow">Linear Regression With Tensorflow</h1>

<p>The benifit of the below code vs using the LinearRegression library is that  Tensorflow will automatically run on GPU if present.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_california_housing</span>

<span class="n">housing</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">()</span>
<span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">housing</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span>
<span class="n">housing_data_plus_bias</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">housing</span><span class="p">.</span><span class="n">data</span><span class="p">]</span>

<span class="c1"># X.shape == (m,n)
</span><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">(</span><span class="n">housing_data_plus_bias</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"X"</span><span class="p">)</span>

<span class="c1"># y.shape == (n,1)
</span><span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">(</span><span class="n">housing</span><span class="p">.</span><span class="n">target</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"y"</span><span class="p">)</span>

<span class="c1"># XT.shape == (n,m)
</span><span class="n">XT</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># theta = (X.T . X)^-1 . X.T . y
</span><span class="n">theta</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">matrix_inverse</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">XT</span><span class="p">,</span> <span class="n">X</span><span class="p">)),</span> <span class="n">XT</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">theta_value</span> <span class="o">=</span> <span class="n">theta</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<h1 id="gradient-descent-with-tensorflow">Gradient Descent with Tensorflow</h1>

<h2 id="concept">Concept</h2>

<ul>
  <li>We are using $$w$$ instead of $\theta$ as this shall be the norm in deep learning.</li>
  <li>$$X$$ is the input column matrix of shape <code class="language-plaintext highlighter-rouge">n x m</code> where <code class="language-plaintext highlighter-rouge">n</code> is the number of features and <code class="language-plaintext highlighter-rouge">m</code> is the dataset size.</li>
  <li>$$W$$ are the weights (parameters) that need to be adjusted after each iteration to increase the accuracy of the prediction.</li>
  <li>$$J$$ is the cost function.</li>
</ul>

<p>Repeat the following for each <code class="language-plaintext highlighter-rouge">j</code> from <code class="language-plaintext highlighter-rouge">1 to n</code>.</p>

<p>$$
\begin{aligned}
w =  (w _{0} ,\ w _{1} ,\ w _{2} ,\ …,\ w _{n}) <br>
w _{j} \ =\ w _{j} \ -\ \alpha \frac{\partial }{\partial w _{j}} J(w) <br>
\end{aligned}
$$</p>

<p>In case of Linear Regression</p>

<p>$$
\begin{aligned}
J = \frac{1}{m}\left[ w^{T}.X -\ y\right]^{2}
\end{aligned}
$$</p>

<p>Solving the partial derivative we get</p>

<p>$$
\begin{aligned}
w \ =\ w \ -\ \alpha \frac{2}{m} \left[ w^{T}.X \ - \ y \ \right].X
\end{aligned}
$$</p>

<h2 id="manually-computing-gradient-descent">Manually computing gradient descent</h2>

<p>The issue with manually computing gradient descent is <em>manual calculation of the derivaties</em>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># X.shape == (n, m) y.shape == (1, m) w.shape == (n, 1)
</span><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">(</span><span class="n">scaled_housing_data_plus_bias</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"X"</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">(</span><span class="n">housing</span><span class="p">.</span><span class="n">target</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"y"</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">"w"</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"predictions"</span><span class="p">)</span>

<span class="c1"># error.shape == (1,m)
</span><span class="n">error</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="n">y</span>
<span class="n">cost_function</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">error</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">"cost_function"</span><span class="p">)</span>

<span class="c1"># gradients.shape == (n, 1)
</span><span class="n">gradients</span> <span class="o">=</span> <span class="mi">2</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">error</span><span class="p">))</span>

<span class="c1"># Adjusted weights
</span><span class="n">training_op</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients</span><span class="p">)</span>

<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="c1"># Print the cost after every 100 iterations
</span>        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Epoch"</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="s">"Cost ="</span><span class="p">,</span> <span class="n">cost_function</span><span class="p">.</span><span class="nb">eval</span><span class="p">())</span>
        <span class="n">training_op</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

    <span class="n">best_w</span> <span class="o">=</span> <span class="n">w</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="autodiff">Autodiff</h2>

<p>Automatically compute the gradients given the nodes <code class="language-plaintext highlighter-rouge">cost_function</code> and <code class="language-plaintext highlighter-rouge">weights</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">cost_function</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<h2 id="optimizer">Optimizer</h2>

<p>Tensorflow provides several optimizers like Gradient/Momentum optimizers that can used to calculate the partial derivatives as follows.</p>

<h3 id="standard-optimizer">Standard Optimizer</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Adjusted weights
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">training_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost_function</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="momentum-optimizer">Momentum Optimizer</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Adjusted weights
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">MomentumOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">training_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost_function</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="placeholder-node">Placeholder Node</h1>

<p>Placeholder nodes do not actually perform any computation.</p>

<ul>
  <li>The value for a placeholder node is supplied at runtime</li>
  <li>An exception is thrown if no value is provided for a placeholder node.</li>
</ul>

<h2 id="creating-placeholder-node">Creating Placeholder Node</h2>

<ul>
  <li>Use the <code class="language-plaintext highlighter-rouge">tf.placeholder</code> and provide the output data type and optionally, shape.</li>
  <li>
<code class="language-plaintext highlighter-rouge">None</code> in the dimension indicates <strong>any size</strong>.</li>
</ul>

<p>The following code creates a placeholder <code class="language-plaintext highlighter-rouge">A</code> to store <code class="language-plaintext highlighter-rouge">floats</code> with any number of rows but 3 columns.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="dynamic-values-to-placeholder-node">Dynamic values to Placeholder Node</h2>

<p>While evaluating a node that depends on a placeholder node, the placeholder values are fed using <strong>feed_dict</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">A</span> <span class="o">+</span> <span class="mi">5</span>
<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">B_val_1</span> <span class="o">=</span> <span class="n">B</span><span class="p">.</span><span class="nb">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">:</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]})</span>
    <span class="n">B_val_2</span> <span class="o">=</span> <span class="n">B</span><span class="p">.</span><span class="nb">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">:</span> <span class="p">[[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]]})</span>

<span class="k">print</span><span class="p">(</span><span class="n">B_val_1</span><span class="p">)</span>
<span class="p">[[</span> <span class="mf">6.</span>  <span class="mf">7.</span>  <span class="mf">8.</span><span class="p">]]</span>

<span class="k">print</span><span class="p">(</span><span class="n">B_val_2</span><span class="p">)</span>
<span class="p">[[</span>  <span class="mf">9.</span>  <span class="mf">10.</span>  <span class="mf">11.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">12.</span>  <span class="mf">13.</span>  <span class="mf">14.</span><span class="p">]]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># X is column matrix
# X.shape == (n, m) y.shape == (1, m) w.shape == (n, 1)
</span><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">"X"</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="p">(</span>  <span class="mi">1</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">"y"</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">"w"</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"predictions"</span><span class="p">)</span>

<span class="c1"># error.shape == (1,m)
</span><span class="n">error</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="n">y</span>
<span class="n">cost_function</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">error</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">"cost_function"</span><span class="p">)</span>

<span class="c1"># Tensorflow optimizer computes the gradients
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">MomentumOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">training_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost_fuction</span><span class="p">)</span>

<span class="c1"># Fix the size of each batch
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">m</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span>

<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_count</span><span class="p">):</span>
            <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="n">fetch_batch</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">training_op</span><span class="p">.</span><span class="nb">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">y_batch</span><span class="p">})</span>
            
        <span class="c1"># Print the cost after every 100 iterations
</span>        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Epoch"</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="s">"Cost ="</span><span class="p">,</span> <span class="n">cost_function</span><span class="p">.</span><span class="nb">eval</span><span class="p">())</span>
        <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">training_op</span><span class="p">)</span>

    <span class="n">best_w</span> <span class="o">=</span> <span class="n">w</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>    
    
<span class="k">def</span> <span class="nf">fetch_batch</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="s">'''
	Fetch batch of size `batch_size` starting with `batch_index`
    '''</span>
    <span class="c1"># load the data from disk
</span>    <span class="k">return</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span>    
</code></pre></div></div>

<h1 id="scopes---namespace-for-nodes">Scopes - Namespace for nodes</h1>

<p>Neural networks can result in a graph with several thousand ndoes. It is better organized/visualized by grouping the nodes into namespaces called <strong>scopes</strong>$$-$$<code class="language-plaintext highlighter-rouge">tf.name_scope(&lt;scope name&gt;)</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">'error_scope'</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="n">y</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">error</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">"mse"</span><span class="p">)</span>
</code></pre></div></div>

<p>Note that the nodes in the scope have the scope name attached</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> print<span class="o">(</span>mse.op.name<span class="o">)</span>
error_scope/mse
</code></pre></div></div>

<h1 id="sharing-variables">Sharing Variables</h1>

<h2 id="variable-in-a-scope">Variable in a Scope</h2>

<p>Shared variables are similar to key=value parameters of a function$$-$$It’s optional. Takes the default value if you don’t pass. The only disadvantage with <code class="language-plaintext highlighter-rouge">key=value</code> parameters is that you could have function call with a lot of parameters passed which may look cluttered at times. Enter shared variables with scope.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">"relu"</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"threshold"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
</code></pre></div></div>

<ul>
  <li>Lookup for a node with fully qualified name <code class="language-plaintext highlighter-rouge">relu/threshold</code> (scope + name)</li>
  <li>Since <code class="language-plaintext highlighter-rouge">reuse</code> is <code class="language-plaintext highlighter-rouge">True</code>, an existing variable is used otherwise a new one is created with given <code class="language-plaintext highlighter-rouge">shape</code> and <code class="language-plaintext highlighter-rouge">initalizer</code>
</li>
  <li>If <code class="language-plaintext highlighter-rouge">reuse</code> is <code class="language-plaintext highlighter-rouge">False</code> (by default) then an error is thrown if the variable already exists.</li>
</ul>

<h2 id="example">Example</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Function using shared variable
</span><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">"relu"</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="c1"># Reuse shared variable
</span>        <span class="n">threshold</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"threshold"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>  
        <span class="p">[...]</span>
        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"max"</span><span class="p">)</span>

<span class="c1"># Main
</span><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">"X"</span><span class="p">)</span>

<span class="c1"># Create shared variable, throw error if it already exists -- Hard create
</span><span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">"relu"</span><span class="p">):</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"threshold"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>

<span class="c1"># The relu invocations shall use the threshold 
</span><span class="kn">from</span> <span class="nn">functional</span> <span class="kn">import</span> <span class="n">seq</span>
<span class="n">l</span> <span class="o">=</span> <span class="n">seq</span><span class="p">.</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">).</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">relu</span><span class="p">(</span><span class="n">X</span><span class="p">)).</span><span class="n">to_list</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"output"</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="saving-and-restoring-model">Saving and Restoring Model</h1>

<p>Save model at regular save checkpoints so that in case of crash you can continue from where latest checkpoint.</p>

<h2 id="saving-a-model">Saving a model</h2>

<ul>
  <li>Create a saver object using <code class="language-plaintext highlighter-rouge">tf.train.Saver()</code>
</li>
  <li>Call the <code class="language-plaintext highlighter-rouge">save</code> method to save the model passing <code class="language-plaintext highlighter-rouge">session</code> and checkpoint file.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">Saver</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
    <span class="p">...</span>
	<span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="s">"/tmp/my_model.ckpt"</span><span class="p">)</span>   
    <span class="p">...</span>   
    
</code></pre></div></div>

<h3 id="saving-specific-variables-only">Saving specific variables only</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">Saver</span><span class="p">({</span><span class="s">'weight'</span><span class="p">:</span><span class="n">w</span><span class="p">})</span>
</code></pre></div></div>

<h2 id="restoring-model">Restoring model</h2>

<ul>
  <li>Create a saver object using <code class="language-plaintext highlighter-rouge">tf.train.Saver()</code>
</li>
  <li>Call the <code class="language-plaintext highlighter-rouge">restore</code> method with the <code class="language-plaintext highlighter-rouge">session</code> and checkpoint file.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">Saver</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
    <span class="p">...</span>
    <span class="n">saver</span><span class="p">.</span><span class="n">restore</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="s">"/tmp/my_model.ckpt"</span><span class="p">)</span>
    <span class="p">...</span>
</code></pre></div></div>

<h1 id="visualize-graph--training-curves-using-tensorboard">Visualize Graph / Training Curves using TensorBoard</h1>

<p>To visualize graphs we need to create nodes that generate data specific to TensorBoard. Generate the data and write them to log dirs. These log dirs can be read and visualed by TensorBoard.</p>

<h2 id="construction-phase">Construction phase</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">utcnow</span><span class="p">().</span><span class="n">strftime</span><span class="p">(</span><span class="s">"%Y%m%d%H%M%S"</span><span class="p">)</span>
<span class="n">root_logdir</span> <span class="o">=</span> <span class="s">"tf_logs"</span>

<span class="c1"># The logdir is of the format: tf_logs/run-&lt;timestamp&gt;
</span><span class="n">logdir</span> <span class="o">=</span> <span class="s">"{}/run-{}/"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">root_logdir</span><span class="p">,</span> <span class="n">timestamp</span><span class="p">)</span>

<span class="c1"># mse_summary is the summary node for mse
</span><span class="n">mse_summary</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">scalar</span><span class="p">(</span><span class="s">'MSE'</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>

<span class="c1"># Writer object
</span><span class="n">file_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">logdir</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_default_graph</span><span class="p">())</span>
</code></pre></div></div>

<ul>
  <li>Create log node$$-$$A dir name that has timestamp in it.</li>
  <li>Create summy nodes$$-$$Tensor flow compatible string node for corresponding nodes to be saved$$-$$<code class="language-plaintext highlighter-rouge">tf.summary.scalar</code>
</li>
  <li>Create <code class="language-plaintext highlighter-rouge">tf.summary.FileWriter</code> passing the log node and graph.</li>
</ul>

<h2 id="execution-phase">Execution phase</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">batch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_count</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">batch_index</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Evaluate summary node to get the TesorBoard summary string
</span>        <span class="n">summary_str</span> <span class="o">=</span> <span class="n">mse_summary</span><span class="p">.</span><span class="nb">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">mse</span><span class="p">:</span> <span class="n">mse</span><span class="p">})</span>
        
        <span class="c1"># Step (acts as the x-axis) at which data is obtained
</span>        <span class="n">step</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">*</span> <span class="n">n_batches</span> <span class="o">+</span> <span class="n">batch_index</span>
        
        <span class="c1"># Write the TensorBoard summary string and step to FileWriter
</span>        <span class="n">file_writer</span><span class="p">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary_str</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="visualize-log-dirs">Visualize log dirs</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>tensorboard <span class="nt">--logdir</span> tf_logs/
Starting TensorBoard  on port 6006
</code></pre></div></div>


        </div>

        <div class="card-footer">
            
        </div>

    </div>

</div>
</div>
                <!-- <div id="footer" class="w-100"><div class="footer">
    <div class="footer-col footer-col-1">
    <ul class="contact-list">
      <li>
        <span class="site-author">
           
             Raghunandan.Seshadri
           
        </span>
      </li>

      
      <li><a href="mailto:raghubs81@gmail.com">raghubs81@gmail.com</a></li>
      

      
      <li>
        <a href="https://github.com/cafeduke"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">cafeduke</span></a>

      </li>
      

    </ul>
    </div>

    <div class="footer-col footer-col-2">
     <ul class="contact-list">
        
           <li>Duke notes. Happy learning!</li>
        
     </ul>
    </div>
</div></div> -->
            </div>
        </div>
    </div>

    <!-- JS -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"></script>

<!-- Popper -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>

<!-- Bootstrap -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>

<!-- Material JavaScript on top of Bootstrap JavaScript -->
<script src="/assets/daemonite-material/js/material.min.js"></script>

<!-- Include and configure MathJax -->
<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
      jax: ["input/AsciiMath", "input/TeX", "input/MathML", "output/HTML-CSS"],
      asciimath2jax: {
         delimiters: [['`','`'], ['$$','$$'], ['$','$']]
      },
      "HTML-CSS": {
         preferredFont:"TeX", availableFonts:["STIX","TeX"]
      }
   });
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>

<script src="/assets/js/mermaid.min.js"></script>

<!-- Google analytics -->


<!-- Sidebar -->
<script src="/assets/js/sidebar.js"></script>



   </body>

</html>
