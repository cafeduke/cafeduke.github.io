---
title: Object Detection
categories: dl-cnn
layout: post
mathjax: true
typora-root-url: ../../../
---

{% include toc.html %}

# Introduction

Following is a broad classification of computer vision problems

- Image classification $$-$$ Recognizing if the object is present in the image or not and
- Image classification + Object location $$-$$ Drawing a bounding box (co-ordinates, width and height) around the object.
- Objects detection $$-$$ Classify and detect the location of multiple similar/different objects.

Furthermore, there could many objects of the same type and/or different types in a single image. For example there could be an image with several cars, several cars and a pedestrian, several cars and several pedestrians. 

# Image classification with object location

The section deals with classification of an image (Is one of the objects present?) and locating the object (where is the object present?). This deals with a case where **only one object of one class is present**. 

## Bounding box detection

A typical image classification problem for say 4 classes (Pedestrian, Car, Bike and None) will have a softmax with 4 neurons. In essence, the `y_cap` is just a number ranging from 1-4 indicating the predicted class. 

In case of object localization `y` is a vector with following elements $$\left[ p_c, b_x, b_y, b_w, b_h, c_1, c_2, c_3 \right]$$

| Components of y   | Detail                                                       |
| ----------------- | ------------------------------------------------------------ |
| $$c_1, c_2, c_3$$ | Three different classes of objects $$-$$ Pedestrian, Car, Bike<br />Eg: [0, 1, 0] indicates that a Car is present. |
| $$p_c$$           | Probability that object belonging to any of the classes exists? <br />Eg: A zero indicates no object exists. A one indicates one of the objects exist. |
| $$b_x, b_y$$      | The x and y distances of the **bounding box** measured from left hand top corner. <br /> Eg: $$b_x$$ = 0.4 means x co-ordinate = 40% of the image size. |
| $$b_w, b_h$$      | Width and height of the **bounding box** measured from left hand top corner.<br />Eg: $$b_w$$ = 0.3 means box width = 30% of the image size. |

Note

- If $$p_c$$ = 1 then we know an object is present so, we care about which class and where?
- If $$p_c$$ = 0 then we don't care about the remaining values of `y`.

> For each training image, the expected output `y` is manually generated by **drawing a bounding box** around the image and measuring the co-ordinates $$b_x, b_y$$, measuring the width and height $$b_w, b_h$$ of the bounding box.

## Cost Function

The cost function in case of object classification + object location is

- If $$p_c == 1$$ $$-$$ Distance between the `y_cap` and `y` vectors.
- If $$p_c == 0$$ $$-$$ Distance between the first element of `y_cap` and `y` vectors. That is $$\sqrt{(y\_cap_{p_c} - y_{p_c})^2} $$

# Landmark detection

In certain applications like **facial feature recognition**, we could train a CNN to detect landmark locations on a face. For example, corner of the eye, edges of eye, corner of lip etc.

>  A landmark in general is a distinguished location that stands out or demarks otherwise seamless regions. 

![Landmark](/assets/images/dl/Landmark.png)

In the above the red dots are the landmarks. For each landmark corresponding co-ordinates ($$(l_x, l_y)$$ needs to be recorded. 

With 64 landmarks for a face 

- There are a total of $$ 64 \times 2 = 128 $$ points. 
- One classification probability $$p$$  that detects if the image is a face or not.

The $$y$$ vector will be $$\left[ p, l1_x, l1_y, l2_x, l2_y, l3_x, l3_y, ....., l64_x, l64_y \right]$$

> For each training image, the expected output `y` is manually generated by laboriously recording the landmark points on the face.

A network that identifies landmarks can be used for applications such as

- Emotion detection
- Pose detection for full body landmarks
- Facial effects like add hat, crown, cooling glass