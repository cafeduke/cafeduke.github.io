---
title: Object Detection
categories: dl-cnn
layout: post
mathjax: true
typora-root-url: ../../../
---

{% include toc.html %}

# Introduction

Following is a broad classification of computer vision problems

- Image classification $$-$$ Classifying an image into a class (Car, Pedestrian, Bike etc)
- Single object detection $$-$$ Classify image into a class + drawing a bounding box (co-ordinates, width and height) around the object.
- Multiple objects detection $$-$$ Detect multiple objects in an image.

Furthermore, there could many objects of the same type and/or different types in a single image. For example there could be an image with several cars, bikes and pedestrians. 

# Single object detection

The section deals with classification of an image (This is an image of what?) and locating the object (where is the object present?). This deals with a case where **only one object of one class is present**. 

## Bounding box detection

A typical image classification problem for say 4 classes (Pedestrian, Car, Bike and None) will have a softmax with 4 neurons. In essence, the `y_cap` is just a number ranging from 1-4 indicating the predicted class. 

In case of object localization `y` is a vector with following elements $$\left[ p_c, b_x, b_y, b_w, b_h, c_1, c_2, c_3 \right]$$

| Components of y   | Detail                                                       |
| ----------------- | ------------------------------------------------------------ |
| $$c_1, c_2, c_3$$ | Three different classes of objects $$-$$ Pedestrian, Car, Bike<br />Eg: [0, 1, 0] indicates that a Car is present. |
| $$p_c$$           | Probability that object belonging to any of the classes exists? <br />Eg: A zero indicates no object exists. A one indicates one of the objects exist. |
| $$b_x, b_y$$      | The x and y distances of the **bounding box** measured from left hand top corner. <br /> Eg: $$b_x$$ = 0.4 means x co-ordinate = 40% of the image size. |
| $$b_w, b_h$$      | Width and height of the **bounding box** measured from left hand top corner.<br />Eg: $$b_w$$ = 0.3 means box width = 30% of the image size. |

Note

- If $$p_c$$ = 1 then we know an object is present so, we care about which class and where?
- If $$p_c$$ = 0 then we don't care about the remaining values of `y`.

> For each training image, the expected output `y` is manually generated by **drawing a bounding box** around the image and measuring the co-ordinates $$b_x, b_y$$, measuring the width and height $$b_w, b_h$$ of the bounding box.

## Cost Function

The cost function in case of object classification + object location is

- If $$p_c == 1$$ $$-$$ Distance between the `y_cap` and `y` vectors.
- If $$p_c == 0$$ $$-$$ Distance between the first element of `y_cap` and `y` vectors. That is $$\sqrt{(y\_cap_{p_c} - y_{p_c})^2} $$

# Landmark detection

In certain applications like **facial feature recognition**, we could train a CNN to detect landmark locations on a face. For example, corner of the eye, edges of eye, corner of lip etc.

>  A landmark in general is a distinguished location that stands out or demarks otherwise seamless regions. 

![Landmark](/assets/images/dl/Landmark.png)

In the above the red dots are the landmarks. For each landmark corresponding co-ordinates ($$(l_x, l_y)$$ needs to be recorded. 

With 64 landmarks for a face 

- There are a total of $$ 64 \times 2 = 128 $$ points. 
- One classification probability $$p$$  that detects if the image is a face or not.

The $$y$$ vector will be $$\left[ p, l1_x, l1_y, l2_x, l2_y, l3_x, l3_y, ....., l64_x, l64_y \right]$$

> For each training image, the expected output `y` is manually generated by laboriously recording the landmark points on the face.

A network that identifies landmarks can be used for applications such as

- Emotion detection
- Pose detection for full body landmarks
- Facial effects like add hat, crown, cooling glass

# Detecting multiple objects 

In the previous section we have looked at classification and location of a single object. However, an image could have multiple objects. One of the ways of detecting multiple objects is using a sliding windows detection.

## Sliding windows detection

The sliding window method involves 

1. Train a ConvNet (CNN) that can classify an image into Car, Pedestrian, Bike or None
2. Set crop size to smallest possible
3. For each crop size
   1. Begin cropping from left hand top corner and slide to right and then down to cover the entire image
   2. Feed each crop to the ConvNet to detect objects.
4. Repeat step 3 with the next crop size














