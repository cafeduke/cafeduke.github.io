---
title: Introduction to Convolutional Neural Networks
categories: dl
layout: post
mathjax: true
typora-root-url: ../../../
---

**DRAFT**

----

{% include toc.html %}

# Computer Vision

Computer vision is one of the areas were deep learning performs very well. Deep learning computer vission has the following applications

- Handwriting analysis. Identify plant by the image of its flower/leaf
  - Image classification
- Self driving cars
  - Object detection: Detect other cars and pedestrians
  - Object localization: Determine the location (position and size) of the objects
- Face recoginision $-$ Use face as ID for authentication.
- Face Styling $-$ Add features like hair style, eye style, nose modification etc to the face. 
- New art $-$ Merge images.
- Transfer learning $-$ Ideas learnt in computer vision can be useful in speech recognision.

# Limitation of NN for computer vision

One of the primary limitation of NN the exponential increase in memory, computation resources and computation time required with just average image resolutions by today's standards (Eg resolution: 1000x1000)

Sample neuron overhead calucation for a 1000x1000 image

- Each column in X will be 1000 x 1000 x 3 (considering RGB) = 3 million
- Let the first hidden layer to have only 1000 neurons 
- W1.shape = (1000,  3M) = 3 billion weights

Huge number of neurons greatly increases the chances of *overfitting* and increases computational overhead. However, image size cannot be compromized $-$ Enter CNN (*Convolutional Neural Netrowks*).

# Convolution

Below we take a look at how a basic convolution operation is performed. A single image layer (As against considering 3 channels of RGB) is convolved (operation denoted by '*') with a single filter layer to produce a resultant layer.

## Basic Convolution

The **convolve**  operation requires an **input** layer (6x6 in this case) and a **filter** layer (3x3 in this case) to produce an **ouput** layer.

![Convolution](/assets/images/dl/Convolution.png)

### Operation Details

- The filter layer is super imposed on the input layer starting with the left hand top corner
- The overlapping numbers are multiplied. The products are then added to get the value of a cell in the resultant matrix.
- The following operations are perfomed to fill cells of the resultant matrix
  - The filter is shifted right hand by one cell (stride = 1) as long as possible
  - The filter is shifted down by one cell as long as possible

### Example

Cell (1,2) of the resultant matrix as shown in the diagram above is obtained as follows:

```mathematica
Cell(1,2) = (1*0 + 0*1 + -1*2) + (1*5 + 0*8 + -1*9) + (1*7 + 0*2 + -1*5)
Cell(1,2) = (0+0-2) + (5+0-9) + (7+0-5)
Cell(1,2) = (-2) + (-4) + (2)
Cell(1,2) = -4
```

## Filter

The input/output image is analogous to a NN layer and the filter is analogous to the weight.  

Filter detects a pattern. 

- To establish this consider a gray scale image. 
- Higher value gets a whiter shade and lower value gets darker shade.
- With this convention, the above filter has stripes from light to dark. (1 is lightest and -1 is darkest)
- In essense, the above filter detects vertical edges.

### Standard filter - Vertical edge detection

In the below example the vertical edge detector filter (with transitions from light to dark, as seen above) is applied to an image. 

#### Example


![VerticalEdge](/assets/images/dl/VerticalEdge.png)



#### Obervation - Selected Cell 

- Green square 
  - It is just a light box (number 10s only) without any edges
  - The corresponding resultant matrix cell has 0 which indicates there is no edge detection.
- Red square
  - Here we have light to dark transition
  - The corresponding resultant matrix cell has 30 which indicates an edge detection. 
  - A positive number indicates that edge transition is from light to dark (accordance with filter).

#### Obervation - Overall

- The input image has light and dark colums
- After convolution we see that the resultant layer identifies a thick white edge (number 30s) right in the middle.
- The resultant convolution is referrering to the vertical edge seperating the light layer (number 10s) from the dark layer (number 0s)

#### Conclusion

The output image indicates that the input image has a vertical edge in the center. The filter acts as vertical edge detector.

### Standard filter - Horizontal edge detection

In the image is like a chess board with both vertical and horizontal images.

#### Example

![ChessBox](/assets/images/dl/ChessBox.png)



#### Obervation - Selected Cell 

- Blue Square	$-$ No edge. Resultant value = 0.
- Green Square $-$ Horizontal edge found. Resultant value = 30.
- Yellow Sqaure $-$ Two horizontal edge. The positive one (Goes from 10 to 0. In accordance with filter) is larger than the negative one (Goes from 0 to 10). Resultant value = 10
- Purple square $-$ Horizontal edge found, but negative. Resultant value = -30.

### Calculation

Let `nxn` be the size of input matrix and `fxf` be the size of the filter.
$$
Output \ Layer \ Size = \ (n-f+1, n-f+1)
$$


## Padding

Padding is a process of making the input matrix larger by surrounding the existing matrix with a padded value. By convention, the padded value is zero.

### Why Padding?

Following is observed in convolution operation

- The corner/edge cells of input matrix are involved in fewer computations.
- The cells in the middle are involved in more computations
- The size of resultant matrix shrinks

The above behavior results in following issues

- The information in corner/edge cells are not utilized to optimum.
- **Shrinking output** $-$ With shrinking image applying multiple convolutions becomes impractical.

### Calculation

Let `nxn` be the size of input matrix and `fxf` be the size of the filter and `p` be the padding count.
$$
Output \ Layer \ Size \ = \ (n+2p-f+1, n+2p-f+1)
$$



### Padding to prevent shringking output

If we have to ensure that the output layer size should be `n` then the required padding can ge figured as follows
$$
\begin{gathered}
n + 2p -f + 1 = n \\
p = \frac{f - 1}{2} \\
\end{gathered}
$$

> Filter is typically odd sized, so padding will typically be symmetric.



## Stride

Shride tells the number of cells to hop (to the right and down) while performing computations. It is analogous to the increment count in a for loop. By default, stride is 1.

![Stride](/assets/images/dl/Stride.png)

Let `nxn` be the size of input matrix and `fxf` be the size of the filter and `p` be the padding count and `s` be the stride.
$$
Output \ Layer \ Size = \left[ \ \left\lfloor {\frac{n+2p-f}{s} + 1}\right\rfloor, \left\lfloor \frac{n+2p-f}{s} + 1 \right\rfloor \ \right]
$$

> The flooring division ensures that the filter boundry does not go out of the input matrix.