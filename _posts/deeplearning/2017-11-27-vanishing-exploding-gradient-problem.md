---
title: Vanishing and exploding gradients problem
categories: dl
layout: post
mathjax: true
---

{% include toc.html %}

# Introduction

In NN, especially deep neural networks the derivative can get exponentially small or exponentially large referred to as vanishing or exploding gradient respectively. 



# Sample network

$$
Z1 = W1*X = b1
A1 = g(Z1)
Z2 = W2+
$$

